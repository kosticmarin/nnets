{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Associative memory\n",
    "\n",
    "## 2.1 Forming the correlation matrix directly\n",
    "\n",
    "In this part of the exercise we will use the direct approach in forming the correlation matrix. Memory based on the correlation matrix should memorize input-output association pairs represented as vectors. For each input vector (key) the memory has to memorize the output pattern i.e. vector in an ASCII code formulation. In this example we will use 4-dimensional input and output vectors. Words (output vectos) that have to be memorized are: '*vrat*' , '*kraj*' , '*cres*' , '*otac*'. Vectors $b_i$, which represent those words should be formed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118]\n",
      " [114]\n",
      " [ 97]\n",
      " [116]]\n",
      "\n",
      "[[107]\n",
      " [114]\n",
      " [ 97]\n",
      " [106]]\n",
      "\n",
      "[[ 99]\n",
      " [114]\n",
      " [101]\n",
      " [115]]\n",
      "\n",
      "[[111]\n",
      " [116]\n",
      " [ 97]\n",
      " [ 99]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "real=lambda x: np.array([[ord(character) for character in x]]).T\n",
    "\n",
    "b1=real(\"vrat\")\n",
    "b2=real(\"kraj\")\n",
    "b3=real(\"cres\")\n",
    "b4=real(\"otac\")\n",
    "print (b1)\n",
    "print()\n",
    "print (b2)\n",
    "print()\n",
    "print (b3)\n",
    "print()\n",
    "print (b4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Orthogonal input vectors\n",
    "\n",
    "This experiment demonstrates how to create an associative memory. Ortonormalized set of vectors defined as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1.]]\n",
      "[[1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "a1 = np.array([[1, 0, 0, 0]]).T\n",
    "a2 = np.array([[0, 1, 0, 0]]).T\n",
    "a3 = np.array([[0, 0, 1, 0]]).T\n",
    "a4 = np.array([[0, 0, 0, 1]]).T\n",
    "print (np.eye(4)) #can be used insted\n",
    "print (np.hstack((a1,a2,a3,a4))) #can also be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is used as input vector set (set of keys). We form the memory correlation matrix $\\mathbf{M}$ using input output pairs as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118 107  99 111]\n",
      " [114 114 114 116]\n",
      " [ 97  97 101  97]\n",
      " [116 106 115  99]]\n",
      "[[ 118.  107.   99.  111.]\n",
      " [ 114.  114.  114.  116.]\n",
      " [  97.   97.  101.   97.]\n",
      " [ 116.  106.  115.   99.]]\n"
     ]
    }
   ],
   "source": [
    "M = b1 * a1.T + b2 * a2.T + b3 * a3.T + b4 * a4.T\n",
    "print(M)\n",
    "print (np.dot(np.eye(4),np.hstack((b1,b2,b3,b4))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to verify whether the memory is functioning properly, we have to calculate outputs for each input vector. For example, the output for the key $a_1$ can be obtained as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vrat\n",
      "kraj\n",
      "cres\n",
      "otac\n"
     ]
    }
   ],
   "source": [
    "char=lambda x:\"\".join(map(chr, map(int, list(x))))\n",
    "\n",
    "print(char(M@a1))\n",
    "print(char(M@a2))\n",
    "print(char(M@a3))\n",
    "print(char(M@a4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasks**\n",
    "\n",
    "1. What is the response for each key? Were all input-output pairs memorized correctly?\n",
    "2. How many input-output pairs would be memorized if vectors $a_i$ were not normalized?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0]] vrat\n",
      "[[0 1 0 0]] kraj\n",
      "[[0 0 1 0]] cres\n",
      "[[0 0 0 1]] otac\n"
     ]
    }
   ],
   "source": [
    "for k in [a1, a2, a3, a4]:\n",
    "    print(k.T, char(M@k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Correlation matrix properties\n",
    "\n",
    "The goal of this experiment is to demonstrate the capacity of obtained memory. In this part of the exercise we will try to memorize one more (fifth) word ('*mrak*'). In 4-dimensional vector space the maximum number of linearly independent vectors is four. Because of this fact, we pick an arbitrary unit vector as the fifth key, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.70710678]\n",
      " [ 0.        ]\n",
      " [ 0.70710678]\n",
      " [ 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "a5 = (a1 + a3) / np.sqrt(2)\n",
    "print(a5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Form vectors $b_5$ ('*mrak*') and $a_5$ as explained and add them into the memory using the following expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 195.07463915  107.          176.07463915  111.        ]\n",
      " [ 194.61017306  114.          194.61017306  116.        ]\n",
      " [ 165.58935778   97.          169.58935778   97.        ]\n",
      " [ 191.66042559  106.          190.66042559   99.        ]]\n"
     ]
    }
   ],
   "source": [
    "b5 = real(\"mrak\")\n",
    "M_five = b1 * a1.T + b2 * a2.T + b3 * a3.T + b4 * a4.T + b5 * a5.T\n",
    "print(M_five)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasks**\n",
    "\n",
    "1. Was the new association properly memorized?\n",
    "2. Did other associations stay correctly memorized?\n",
    "    - If not - which were not memorized correctly and why?\n",
    "    - If yes - which were memorized correctly and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0]] vrat ÃÂ¥¿\n",
      "[[0 1 0 0]] kraj kraj\n",
      "[[0 0 1 0]] cres °Â©¾\n",
      "[[0 0 0 1]] otac otac\n",
      "[[ 0.70710678  0.          0.70710678  0.        ]] ĆēíĎ\n"
     ]
    }
   ],
   "source": [
    "for k in [a1, a2, a3, a4]:\n",
    "    before=char(M@k)\n",
    "    after=char(M_five@k)\n",
    "    print(k.T, before, after)\n",
    "\n",
    "print(a5.T, char(M_five@a5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Word pairs as associations\n",
    "\n",
    "In this experiment we will form the associative memory, which memorizes word pairs. The associations, which have to be memorized are: *ruka*-*vrat*, *kset*-*kraj*, *more*-*cres*, *mama*-*otac*. Generate input vectors (keys) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47791 47867 46818 44624]\n",
      " [50264 50354 49352 47048]\n",
      " [43019 43124 42263 40271]\n",
      " [47892 48130 47019 44766]]\n"
     ]
    }
   ],
   "source": [
    "a1 = real(\"ruka\")\n",
    "a2 = real(\"kset\")\n",
    "a3 = real(\"more\")\n",
    "a4 = real(\"mama\")\n",
    "M = b1 * a1.T + b2 * a2.T + b3 * a3.T + b4 * a4.T\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectors bi don't have to be created again because they are the ones used in the first part of the exercise. Form the matrix M using the same procedure as in the first part of the exercise.\n",
    "\n",
    "**Tasks**\n",
    "\n",
    "1. What is the response for each input key?\n",
    "2. Which associations were memorized correctly?\n",
    "3. Which associations were not memorized correctly and why?\n",
    "4. How can we fix this problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47791 47867 46818 44624]\n",
      " [50264 50354 49352 47048]\n",
      " [43019 43124 42263 40271]\n",
      " [47892 48130 47019 44766]]\n",
      "[[114]\n",
      " [117]\n",
      " [107]\n",
      " [ 97]]\n",
      "[[20386667]\n",
      " [21465834]\n",
      " [18378102]\n",
      " [20464233]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "chr() arg not in range(0x110000)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c8c17a3fdee8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-252f70fb7ad8>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0ma2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0ma3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: chr() arg not in range(0x110000)"
     ]
    }
   ],
   "source": [
    "print(M)\n",
    "for k in [a1, a2, a3, a4]:\n",
    "    print(k)\n",
    "    print(M@k)\n",
    "    print(k, char(M@k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 Input vector orthogonalization\n",
    "\n",
    "In this experiment we show an associative memory, which uses keys that are orthonormalized. We use the Gram-Schmidt orthogonalization method as follows. We first form the matrix $\\mathbf{A}$ using vectors $a_i$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[114 107 109 109]\n",
      " [117 115 111  97]\n",
      " [107 101 114 109]\n",
      " [ 97 116 101  97]]\n"
     ]
    }
   ],
   "source": [
    "A=np.hstack([a1, a2, a3, a4])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this step we perform the orthonormalization step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.50594743  0.14847022 -0.77925491 -0.33872641]\n",
      " [-0.50939047 -0.83525837  0.19795538 -0.06065043]\n",
      " [-0.50546797  0.25257838  0.01775974  0.8248581 ]\n",
      " [-0.47858195  0.46530012  0.59435684 -0.44854773]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.linalg import orth\n",
    "C=orth(A.T)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract individual orthonormal vectors $c_i$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c1=np.array([C[0]]).T\n",
    "c2=np.array([C[1]]).T\n",
    "c3=np.array([C[2]]).T\n",
    "c4=np.array([C[3]]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we form a new matrix $\\mathbf{M}$ using vectors $c_i$ instead of vectors $a_i$ when creating the matrix $\\mathbf{M}$. Verify the responses of matrix $\\mathbf{M}$ with vectors $c_i$ as inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 118.]\n",
      " [ 114.]\n",
      " [  97.]\n",
      " [ 116.]]\n",
      "[[-0.50594743  0.14847022 -0.77925491 -0.33872641]] vrat\n",
      "[[ 107.]\n",
      " [ 114.]\n",
      " [  97.]\n",
      " [ 106.]]\n",
      "[[-0.50939047 -0.83525837  0.19795538 -0.06065043]] kraj\n",
      "[[  99.]\n",
      " [ 114.]\n",
      " [ 101.]\n",
      " [ 115.]]\n",
      "[[-0.50546797  0.25257838  0.01775974  0.8248581 ]] cres\n",
      "[[ 111.]\n",
      " [ 116.]\n",
      " [  97.]\n",
      " [  99.]]\n",
      "[[-0.47858195  0.46530012  0.59435684 -0.44854773]] otac\n"
     ]
    }
   ],
   "source": [
    "M = b1 * c1.T + b2 * c2.T + b3 * c3.T + b4 * c4.T\n",
    "for c in [c1, c2, c3, c4]:\n",
    "    print(M@c)\n",
    "    print(c.T, char(M@c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasks**\n",
    "\n",
    "1. What is the effect of vector orthonormalization?\n",
    "2. How many pairs were correctly memorized?\n",
    "3. What can we expect when normalizing the vectors?\n",
    "4. What can we expect when only orthogonalizing the vectors?\n",
    "5. What can we expect if vectors $c_i$ are linearly independent but not orthogonal?\n",
    "\n",
    "### 2.1.5 Finding the correlation matrix using matrix inversion\n",
    "\n",
    "For previously used word pairs (*ruka*-*vrat*, *kset*-*kraj*, *more*-*cres*, *mama*-*otac*) find a $4\\times 4$ correlation matrix $\\mathbf{M}$ as $\\mathbf{M} = \\mathbf{B}\\mathbf{A}^{-1}$, where matrix $\\mathbf{B}$ is defined as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118 107  99 111]\n",
      " [114 114 114 116]\n",
      " [ 97  97 101  97]\n",
      " [116 106 115  99]]\n",
      "[[ 2.61453831 -0.42249469 -1.18860108 -0.03551725]\n",
      " [ 0.86259171 -0.29902568  0.16622243  0.33881185]\n",
      " [ 0.11877619  0.02550434  0.55198385  0.220755  ]\n",
      " [-0.34587034  1.00278743  0.66319844 -0.33875405]]\n"
     ]
    }
   ],
   "source": [
    "B=np.hstack([b1, b2, b3, b4])\n",
    "print(B)\n",
    "M=B@np.linalg.inv(A)\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasks**\n",
    "\n",
    "1. Were all associations properly memorized? Remark: The result should be rounded to the nearest number before comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[114 117 107  97]] vrat\n",
      "[[107 115 101 116]] kraj\n",
      "[[109 111 114 101]] cres\n",
      "[[109  97 109  97]] otac\n"
     ]
    }
   ],
   "source": [
    "for a in [a1, a2, a3, a4]:\n",
    "    print(a.T, char(np.round(M@a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.6 Finding the correlation matrix using pseudo-inversion\n",
    "\n",
    "A pseudo-inverse matrix can be used in order to find the correlation matrix when number of associations is larger than dimensionality of vectors representing the associations. In this case, the correlation matrix can be found as $\\mathbf{M} = \\mathbf{B}\\mathbf{A}^{+}$, where $\\mathbf{A}^{+}$ is a pseudo-inverse matrix defined as $\\mathbf{A}^{+} = \\mathbf{A}^{T}(\\mathbf{A}\\mathbf{A}^{T})^{-1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that the vectors $a_i$ and $b_i$ are defined previously (five associations in total). Find the pseudo-inverse matrix for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.          0.          0.          0.70710678]\n",
      " [ 0.          1.          0.          0.          0.        ]\n",
      " [ 0.          0.          1.          0.          0.70710678]\n",
      " [ 0.          0.          0.          1.          0.        ]]\n",
      "[[118 107  99 111 109]\n",
      " [114 114 114 116 114]\n",
      " [ 97  97 101  97  97]\n",
      " [116 106 115  99 107]]\n",
      "[[ 0.75        0.         -0.25        0.        ]\n",
      " [ 0.          1.          0.          0.        ]\n",
      " [-0.25        0.          0.75        0.        ]\n",
      " [ 0.          0.          0.          1.        ]\n",
      " [ 0.35355339  0.          0.35355339  0.        ]]\n",
      "[[ 102.28731957  107.           83.28731957  111.        ]\n",
      " [  97.30508653  114.           97.30508653  116.        ]\n",
      " [  81.79467889   97.           85.79467889   97.        ]\n",
      " [  96.08021279  106.           95.08021279   99.        ]]\n"
     ]
    }
   ],
   "source": [
    "a1 = np.array([[1, 0, 0, 0]]).T\n",
    "a2 = np.array([[0, 1, 0, 0]]).T\n",
    "a3 = np.array([[0, 0, 1, 0]]).T\n",
    "a4 = np.array([[0, 0, 0, 1]]).T\n",
    "\n",
    "a5 = (a1 + a3) / np.sqrt(2)\n",
    "\n",
    "A=np.hstack([a1, a2, a3, a4, a5])\n",
    "print(A)\n",
    "B=np.hstack([b1, b2, b3, b4, b5])\n",
    "print(B)\n",
    "A_pseudo=A.T@np.linalg.inv(A@A.T)\n",
    "print(A_pseudo)\n",
    "M=B@A_pseudo\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasks**\n",
    "\n",
    "1. Were all pairs memorized correctly?\n",
    "2. If not, what is the error between expected and obtained values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0]] faR`\n",
      "[[0 1 0 0]] kraj\n",
      "[[0 0 1 0]] SaV_\n",
      "[[0 0 0 1]] otac\n",
      "[[ 0.70710678  0.          0.70710678  0.        ]] w\n",
      "\n",
      "error for each association\n",
      "[[ 15.71268043]\n",
      " [ 16.69491347]\n",
      " [ 15.20532111]\n",
      " [ 19.91978721]]\n",
      "\n",
      "error for each association\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "\n",
      "error for each association\n",
      "[[ 15.71268043]\n",
      " [ 16.69491347]\n",
      " [ 15.20532111]\n",
      " [ 19.91978721]]\n",
      "\n",
      "error for each association\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "\n",
      "error for each association\n",
      "[[-22.22108576]\n",
      " [-23.61017306]\n",
      " [-21.50357134]\n",
      " [-28.17083323]]\n"
     ]
    }
   ],
   "source": [
    "e = [0,0,0,0]\n",
    "for a in [a1, a2, a3, a4, a5]:\n",
    "    print(a.T, char(np.round(M@a)))\n",
    "ai = [a1,a2,a3,a4,a5]\n",
    "bi = [b1,b2,b3,b4,b5]\n",
    "for a,b in zip(ai,bi):\n",
    "    print()\n",
    "    print('error for each association')\n",
    "    print(b - M@a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Finding the correlation matrix using supervised learning\n",
    "\n",
    "This experiment shows us how to form the matrix $\\mathbf{M}$ using supervised learning. In two following experiments we will use learning with error correction.\n",
    "\n",
    "### 2.2.1 Learning with error correction\n",
    "\n",
    "Form matrices $\\mathbf{A}$ and $\\mathbf{B}$ where each contains 4 vectors stacked in columns as explained in previous experiments. Check the contents of obtained matrices with following operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[114 107 109 109]\n",
      " [117 115 111  97]\n",
      " [107 101 114 109]\n",
      " [ 97 116 101  97]]\n",
      "[[118 107  99 111]\n",
      " [114 114 114 116]\n",
      " [ 97  97 101  97]\n",
      " [116 106 115  99]]\n"
     ]
    }
   ],
   "source": [
    "a1=real(\"ruka\")\n",
    "a2=real(\"kset\")\n",
    "a3=real(\"more\")\n",
    "a4=real(\"mama\")\n",
    "\n",
    "b1=real(\"vrat\")\n",
    "b2=real(\"kraj\")\n",
    "b3=real(\"cres\")\n",
    "b4=real(\"otac\")\n",
    "\n",
    "A=np.hstack([a1, a2, a3, a4])\n",
    "print(A)\n",
    "B=np.hstack([b1, b2, b3, b4])\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to start the learning procedure we have to initialize the matrix $\\mathbf{M}$ (For example, random values uniformly generated in $[-0.5, 0.5]$ interval):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.23114683 -0.37107041  0.28461405  0.30829767]\n",
      " [ 0.20530958 -0.40018105 -0.02733057 -0.07252721]\n",
      " [-0.20729085 -0.3943859   0.30004219  0.15681216]\n",
      " [-0.35034386 -0.12918787  0.06338021  0.18924809]]\n"
     ]
    }
   ],
   "source": [
    "M=np.random.rand(4, 4)-0.5\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the learning part use the function *trainlms*, which is the implementation of the Widrow-Hoff LMS learning algorithm. The function can be used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainlms(A, B, M, ni, max_num_iter, min_err=0.02):\n",
    "    d=B\n",
    "    x=A\n",
    "    w=M\n",
    "    \n",
    "    n=0\n",
    "    err=[]\n",
    "    while (n<max_num_iter):\n",
    "        n+=1\n",
    "        e=d-w@x\n",
    "        w+=ni*np.dot(e, x.T)\n",
    "        err.append(np.sum(np.sum(np.multiply(e, e))))\n",
    "        if (err[-1]<min_err):\n",
    "            break\n",
    "    return w, err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where *max_num_iter* is the number of iterations and *ni* is the learning rate. Find the *max_num_iter* variable experimentally. For *ni* you can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ni=0.9999/np.linalg.eig(A @ A.T)[0].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function trainlms performs the learning until SSE drops below $0.02$ or maximum number of iterations is performed. After the learning phase, look at the responses of the correlation matrix $\\mathbf{M}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M, e=trainlms(A, B, M, ni, 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True]], dtype=bool)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(M@A)==B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will see, which characters were properly reconstructed: the positions with correct reconstructions will have value *True* and  other positions will have value *False*. By calling the *trainlms* multiple times we can extend the learning process and maybe increase the number of memorized characters but the proper way to extend the learning process is to increase the *max_num_iter* variable. We can draw a graph, which plots the error with number of iterations (in logaritmic scale) using the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEOCAYAAACetPCkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ab54a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(e)\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasks**\n",
    "\n",
    "1. Plot a graph showing number of memorized characters tied to number of used iterations. (Caution: When building the graph, start the simulation with the same starting matrix.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEOCAYAAACEiBAqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XmYXHWZ9vHv3Z09JOmQNFuSJiQs\ngmxCswjKIsigIiiujKgor3EbxGGcEcaFVx1HxUHH9cWMYpgZBkF0EBxEEEHGDQhhCQgICSiBYDpr\npzu9pp/3j3M66XR6OVXdVadTdX+uq69UnTp9fk8finrqtysiMDOz6lWTdwBmZpYvJwIzsyrnRGBm\nVuWcCMzMqpwTgZlZlXMiMDOrck4EZmZVzonAzKzKORGYmVU5JwIzsyo3Lu8Aspg9e3bMnz8/7zDM\nzHYpDzzwwNqIqB/uvF0iEcyfP5+lS5fmHYaZ2S5F0p+ynOemITOzKudEYGZW5ZwIzMyqnBOBmVmV\nK1kikHS1pDWSHu13/CJJT0p6TNIVpSrfzMyyKWWNYAlwZt8Dkk4FzgEOj4iXAv9SwvLNzCyDkg0f\njYh7JM3vd/iDwBcjoiM9Z02pyjez4T2yaiN/ae7IOwwbwssa6pi928SSllHueQQHAq+U9HmgHfhY\nRNw/0ImSFgGLABoaGsoXoVmVaO3o5o3f/i1be7xv+Vi25D3HcMpBe5S0jHIngnHATOB44BjgBkkL\nImKnd2JELAYWAzQ2NvqdajbKNrZ1sbUn+MhpB3DGIXvmHY4NomHWlJKXUe5EsAr4cfrBf5+kHmA2\n0FTmOMyqXkt7NwAv2Wsah86ZkXM0lqdyDx+9CXgVgKQDgQnA2jLHYGZAS0cXALtN3CVWmrESKtk7\nQNJ1wCnAbEmrgMuBq4Gr0yGlncC7B2oWMrPS25zWCHab5ERQ7Uo5aui8QV46v1Rlmll2LR1JIpjm\nGkHV88xisyrV4hqBpZwIzKpUb43AfQTmRGBWpXr7CKZOcCKodk4EZlWqpaOb3SaOo6ZGeYdiOXMi\nMKtSLe3dbhYywInArGq1dHS7o9iAXWTPYjMbPR++dhl3PbmG9q6tHD63Lu9wbAxwIjCrMvc+s559\nZ03lFfvP4uQDS7uYme0anAjMqkxzexdvOnoOl73m4LxDsTHCfQRmVaS9ayud3T1MnzQ+71BsDHEi\nMKsize3JQnPT3UlsfTgRmFWR5rZkEtn0ya4R2HZOBGZVZHuNwInAtnMiMKsizW1pIpjspiHbzonA\nrIr0ri/kGoH1VbJEIOlqSWvSTWj6v/YxSSFpdqnKN7OdbWsach+B9VHKGsES4Mz+ByXNA14N/LmE\nZZvZAHo7i6d51JD1UbJEEBH3AOsHeOmrwD8A3qLSrMya27sYVyMmj6/NOxQbQ8raRyDpbOD5iHi4\nnOWaWaK5rYvpk8cjeelp265s9UNJU4BPAGdkPH8RsAigoaGhhJGZVY/m9m5PJrOdlLNGsBDYD3hY\n0rPAXGCZpL0GOjkiFkdEY0Q01tfXlzFMs8q1ub3LHcW2k7J9NYiI5cC2pQ7TZNAYEWvLFYNZtWtu\n6/LQUdtJKYePXgf8DjhI0ipJF5aqLDPLprm925PJbCcle0dExHnDvD6/VGWb2cBcI7CBeGaxWRVp\nbu/yHALbiROBWZXo7O6hvct7EdjOnAjMqsRmLy9hg3AiMKsSzb0Lzrmz2PpxIjCrEtuWoHbTkPXj\nRGBWJbzyqA3GicCsSmzbptI1AuvHicCsSmyvEbiPwHY0bCKQdIWk6ZLGS7pT0lpJ55cjODMbPb2j\nhqa5RmD9ZKkRnBERzcBZwCrgQODvSxqVmY265rZuagRTJ3gvAttRlkTQ+/XhtcB1ETHQZjNmNsY1\nt3svAhtYlsbCmyU9AbQBH5JUD7SXNiwzG21eZ8gGM2SNQFINcAvwcpIlo7uALcA5ZYjNzEaRVx61\nwQyZCCKiB7gyIjZExNb0WGtEvFiW6Mxs1LhGYIPJ0kdwu6Q3yQ2LZru05nYnAhtYlnriJcBUYKuk\nNkBARMT0kkZmZqNqc3u3l6C2AQ1bI4iIaRFRExHjI2J6+nzYJCDpaklrJD3a59iXJT0h6RFJ/y2p\nbqR/gJll09zm/YptYFkmlEnS+ZI+lT6fJ+nYDNdeApzZ79gdwKERcTjwR+CyAuM1syJ0b+2htXOr\nm4ZsQFn6CL5NMmror9PnLcC3hvuliLgHWN/v2O0R0Z0+/T0wN3uoZlaszV6C2oaQ5V1xXEQcJelB\ngIjYIGnCKJT9XuD6UbiOmQ1iyW+e4Tv3rKS7JwAvOGcDy5IIuiTVAgGQTijrGUmhkj4BdAPXDnHO\nImARQENDw0iKM6ta9zy1ls7uHk47eA8mjqvlpAPr8w7JxqAsieDrwH8De0j6PPBm4FPFFijp3STr\nFp0WETHYeRGxGFgM0NjYOOh5Zja4DVs6OWSf6Vzx5iPyDsXGsGETQURcK+kB4DSSoaNviIjHiylM\n0pnAx4GTI2JLMdcws+w2buli7swpeYdhY9ywiUDSf0TEO4EnBjg21O9dB5wCzJa0CricZJTQROCO\ndH7a7yPiA8WHb2ZD2bClk5lT3C9gQ8vSNPTSvk/S/oKjh/uliDhvgMPfyxiXmY3Q1p5gU1sXdZ47\nYMMYdPiopMskbQYOl9Sc/mwG1gA3ly1CMytKc1sXEVA3ZTQG+VklGzQRRMQXImIa8OV0RnHvrOJZ\nEXFpGWM0syJsbEt2JJs51TUCG1qWCWU7zSKWdGcJYjGzUbRhSyfgGoENb9A+AkmTSBabmy1pJsmI\nIYDpwD5liM3MRmBjmghmOhHYMIbqLH4/8FGSD/1lfY43k2GJCTPL14bWtGnIo4ZsGIMmgoj4GvA1\nSRdFxDfKGJOZjQI3DVlWWfoIrpb0SUmLASQdIOmsEsdlZiO0cUsXNYJpE73QnA0tUyIAOoET0uer\ngH8qWURmNio2bOmkbsoEamq8uaANLUsiWBgRVwBdABHRu0uZmY1hG7d0Uef+AcsgSyLolDSZ7auP\nLgQ6ShqVmY1YsryE+wdseFkaDy8HbgPmSboWOBG4oJRBmdnIbdzSxT51k/IOw3YBWVYfvUPSMuB4\nkiahiyNibckjM7MR2ZguQW02nKEmlB3V79Dq9N8GSQ0Rsaz/75jZ2LFhS5fnEFgmQ9UIrhzitQBe\nNcqxmNkoae/aSlvXVs8hsEyGmlB2ajkDMbPRs3FLMqvYo4YsiyyjhsxsF7PB6wxZAUqWCCRdLWmN\npEf7HNtd0h2Snkr/nVmq8s2q2fblJVwjsOGVskawBDiz37FLgTsj4gDgzvS5mY2y3qYh1wgsi2ET\nwUB7D2TZjyAi7gHW9zt8DnBN+vga4A0ZYjSzArlpyAox3H4EUxjd/Qj2jIjVABGxWtIeRV7HzIbg\nzmIrRNb9CB5geyIoy34EkhYBiwAaGhpKXZxZRdm4pZPJ42uZNL4271BsFzDUnsVfi4j9gI9FxIKI\n2C/9OSIivllkeX+RtDdA+u+aIcpfHBGNEdFYX19fZHFm1WmDF5yzAmTpLO6RVNf7RNJMSR8qsryb\ngXenj98N/KTI65jZEDamS1CbZZElEbwvIjb2PomIDcD7hvslSdcBvwMOkrRK0oXAF4FXS3oKeHX6\n3MxGmZeXsEJkWX20RpIioncZ6lpg2K8aEXHeIC+dVkB8ZlaEDVs6OXgvLzhn2WRJBD8HbpB0Fcka\nQx8gWZbazMYob0pjhciSCD5OMoLogyQjh24HvlvKoMyseD09wUZvSmMFyLIfQY+kJcAvI+LJ0odk\nZiOxub2bnvAcAssuy8zis4GHSJuDJB0p6eZSB2ZmxdnY1rvOkGsElk2WUUOXA8cCGwEi4iFgfglj\nMrMR2LBtnSHXCCybLImgOyI2lTwSMxsV21cedY3AssnSWfyopL8GaiUdAHwE+G1pwzKzQj3xYjN/\n/8NHWNfSAbhGYNllqRFcBLwU6AD+C9hEsgaRmY0h965cz/LnN3HIPtM5//gG9p01Ne+QbBcxZI0g\nnTz2mYj4e+AT5QnJzIqxrqUDCb7zzkZqazT8L5ilhqwRRMRW4OgyxWJmI7C2tZPdp0xwErCCZekj\neDAdLvpDoLX3YET8uGRRmVnB1rV0MGs3dxBb4bIkgt2BdcCr+hwLwInAbAxZ19LJrKkT8w7DdkFZ\n+ggeiYivlikeMyvSutZOXrqPF5qzwmXpIzi7TLGY2Qisbelg9m6uEVjhsjQN/VbSN4Hr2bGPYFnJ\nojKzgnR0b2VzezezprqPwAqXJRGckP772T7Hgh37DAoi6W+B/5NeZznwnohoL/Z6ZtVufWsym3iW\nawRWhCyrj546mgVKmkMyO/mQiGiTdAPwdmDJaJZjVk3WtfQmAtcIrHBZVh+dIekrkpamP1dKmjHC\ncscBkyWNA6YAL4zwemZVbW26rMRsJwIrQpYlJq4GNgNvTX+age8XW2BEPA/8C/BnYDWwKSJuL/Z6\nZtanRuDho1aELIlgYURcHhEr05/PAAuKLVDSTOAcYD9gH2CqpPMHOG9Rby2kqamp2OLMqsK61qRG\n4KYhK0aWRNAm6RW9TySdCLSNoMzTgWcioikiukgmpp3Q/6SIWBwRjRHRWF9fP4LizCrfupZOJoyr\nYbeJWcZ/mO0oy7vmg8A1ffoFNgAXjKDMPwPHS5pCklBOA5aO4HpmVW9tSyezp05A8jpDVrgso4Ye\nAo6QND193jySAiPiXkk3AsuAbuBBYPFIrmlW7da1dnjoqBUty6ihf5ZUFxHNEdEsaaakfxpJoWmf\nw0si4tCIeGdEdIzkembVbl1Lp/sHrGhZ+gheExEbe59ExAbgtaULycwKta6lwyOGrGhZEkGtpG3v\nMEmTAb/jzMaIiGBta6fnEFjRsnQW/ydwp6TvkywJ8V7gmpJGZWaZtXR009nd46YhK1qWzuIrJD1C\nMuxTwOci4uclj8zMMvFkMhupTIOOI+I24LYSx2JmRfBkMhupLH0EZjaGrU1rBN6LwIrlaYhmu4ie\nnmB1886rta9sSrYJcY3AijVoIpB0Z0ScJulLEfHxcgZlZjv70m1P8J17Vg742rgasbs3pbEiDVUj\n2FvSycDZkn5A0lG8jXcoMyuvP6xuZt9ZU/jwKfvv9Nrc3SczcVxtDlFZJRgqEXwauBSYC3yl32sj\n2qHMzAq3elM7L9lrGm89Zl7eoViFGTQRRMSNwI2SPhURnytjTGbWT0SwemMbr9h/dt6hWAXKMo/g\nc5LOBk5KD90dET8tbVhm1ldzezetnVvZp25S3qFYBcqy6NwXgIuBP6Q/F6fHzKxMVm9KtgDZe8bk\nnCOxSpRl+OjrgCMjogdA0jUkS0dfVsrAzGy71RuTYaOuEVgpZJ1QVtfn8Ug3rjezAr3gGoGVUJYa\nwReAByXdRTKE9CRcGzArq9Ub26kR7DHNs4dt9GXpLL5O0t3AMSSJ4OMR8eJICpVUB3wXOJR0RdOI\n+N1IrmlWyV7Y1Mae0ycxrtarwtjoy7ro3Grg5lEs92vAbRHxZkkTgCmjeG2zirN6Yzt7z3D/gJVG\n2b9epHsfnwR8DyAiOvvugGZmO1u9qY2969w/YKWRRz1zAdAEfF/Sg5K+K2lqDnGYjXlLn13P277z\nO57b0MY+rhFYiQyZCCTVSHp0lMscBxwF/L+IeBnQSrKURf+yF0laKmlpU1PTKIdgtmu4dfmLLPvz\nBk5YOIvXHLZ33uFYhRoyEaRzBx6W1DCKZa4CVkXEvenzG0kSQ/+yF0dEY0Q01tfXj2LxZruOVRu2\nsN/sqfzHhcdxVMPMvMOxCpWls3hv4DFJ95F8ewcgIs4upsCIeFHSc5IOiogngdNIZiybWT+rNrQx\nd6bHUlhpZUkEnylBuRcB16YjhlYC7ylBGWa7vFUbttA43zUBK60s8wh+JWlf4ICI+IWkKcCIFj6P\niIeAxpFcw6zSbWrrorm9m7kzPVrISivLonPvI2nH/056aA5wUymDMjN4fkOyrISbhqzUsgwf/TBw\nItAMEBFPAXuUMigzS5qFANcIrOSyJIKOiOjsfSJpHMmyEGZWQqtcI7AyyZIIfiXpH4HJkl4N/BC4\npbRhmdmqDW1MmVDLzCnj8w7FKlyWRHApyUzg5cD7gVuBT5YyKDNLmobmzpyMpLxDsQqXZdRQT7oZ\nzb0kTUJPRoSbhsxKzHMIrFyGTQSSXgdcBawgWYZ6P0nvj4iflTo4s0rU0b2V+55ZzysP2HHG/Ob2\nLm5dvpqurcn3rD+ta/UcAiuLLBPKrgROjYinASQtBP4HcCIwK8Jtj77IxT94iNv/9iQO3HPatuM/\nXLqKz/50x0n2h+7jDQGt9LIkgjW9SSC1ElhTonjMKt66lmQQ3uOrm3dIBE83tTBj8njuuOQkAGol\nZu3mHcms9AZNBJLOTR8+JulW4AaSPoK3APeXITazirS5vRuAJ1/cvMPxZ5paWVA/lT2meblpK6+h\nagSv7/P4L8DJ6eMmwA2XZkVqbu8C4I9/2TERrFzbwiv290q7Vn6DJoKI8EJwZiXQ3JYkgif7JILW\njm7+0tzBgnrv0WTll2XU0H4kq4XO73t+sctQm1W73hrBc+vbaO3oZurEcTyzNlnhfb/ZTgRWflk6\ni28i2V/4FqCntOGYVb7mtu5tj59a08KR8+pYmSYC1wgsD1kSQXtEfL3kkZhVieb2LhbWT2VFUyt/\nfHEzR86r45mmJBHMn+VEYOWXJRF8TdLlwO1AR+/BiFhWsqjMKtjm9m6OnFfH8xvbtvUTPLO2hTl1\nk5k0fkRbfZgVJUsiOAx4J/AqtjcNRfq8aJJqgaXA8xFx1kiuZbYraW7vYuaU8Rywx7RtI4dWrm11\ns5DlJksieCOwoO9S1KPkYuBxYPooX9dszIoImtu6mD55PAfuOY3/faqJiOCZplbeeNScvMOzKpVl\n9dGHgbrRLFTSXOB1wHdH87pmY11r51Z6AqZPGs9Be+3Gms0dPPp8M5s7uj1iyHKTpUawJ/CEpPvZ\nsY9gJMNH/xX4B2DacCeaVZLeOQTTJo1j77pk57HXf/PXACys3y23uKy6ZUkEl49mgZLOIlm/6AFJ\npwxx3iJgEUBDQ8NohmCWm97lJaZPHs+JC2fx+TceypaOrUyZWMsJC2flHJ1Vqyz7EfxqlMs8EThb\n0muBScB0Sf8ZEef3K3cxsBigsbHR+x9YReidTDZ90njG1dbwjuP2zTkiswx9BJI2S2pOf9olbZXU\nXGyBEXFZRMyNiPnA24Ff9k8CZpWqt2lo+uQslXGz8shSI9ihHV/SG4BjSxaRWQXrWyMwGyuyjBra\nQUTcxAjnEPS51t2eQ2DVpHd5iemTnQhs7Miy6Ny5fZ7WAI0kE8rMrEB9Rw2ZjRVZ3o199yXoBp4F\nzilJNGYVbnNHN5PH1zK+tuDKuFnJZOkj8L4EZqMkmVXs2oCNLUNtVfnpIX4vIuJzJYjHrKI1t3e5\no9jGnKG+mrQOcGwqcCEwC3AiMCtQc1u3O4ptzBlqq8orex9LmkaySNx7gB8AVw72e2Y2uOb2LmZN\nnZB3GGY7GLKxUtLuwCXAO4BrgKMiYkM5AjMb6zZt6eKTP3mULR3dQ543YVwN//jag5m3+xQ2t3d7\n8xkbc4bqI/gycC7JMg+HRURL2aIy2wX8ZsVabnn4BQ7cczcmjBt4FFAEPPZCM0fMq+MDJy90Z7GN\nSUO9I/+OZLXRTwKfkNR7XCSdxd5HwKraijXJd6ObPnwiUyYM/r/SK6/4JctXbUr2InBnsY1BQ/UR\neKCz2RBWrm1lnxmThkwCAIfPqeOR5zfS3tVD19ZwZ7GNOf6wNyvSiqYWFu4x/B4Ch82dwXPr2/jT\n+mQgnmsENtY4EZgVISJY2dTKggy7ih02ZwYAv316HeCVR23scSIwK8KazR20dHRnqhEcuk+aCFas\nBWCaawQ2xjgRmBVhRVPSUbxg9vCJYMaU8cyfNYXfr1wPwHQvOGdjjBOBWRFWNCXt/Qv3yDYn4NA5\nM2jp8BLUNjY5EZgVYWVTC1Mm1LLX9EmZzj987oxtj91ZbGNN2ROBpHmS7pL0uKTHJF1c7hjMRmpF\nUysL6qfSZ37NkA6bU7ftsfcisLEmjxpBN/B3EXEwcDzwYUmH5BCHWdFWNrVk6h/o9dI5yfzLCeNq\nmDS+tlRhmRWl7IkgIlZHxLL08WbgcWBOueMwK1Zb51ae39jGwvrsiWD6pPEsmD3VzUI2JuXaRyBp\nPvAy4N4BXlskaamkpU1NTeUOzWxQz6xtJQIW1Be2eNwJ+89i/qwpJYrKrHi5NVZK2g34EfDRiGju\n/3pELCZZ8I7GxkbvkWxjxsq1ydDRQmoEAJ8+66X0hN/KNvbkkggkjSdJAtdGxI/ziMGsWCvWJENH\n98swq7ivwVYoNctbHqOGBHwPeDwivlLu8s1GauXaFubUTWbyBHf6WmXI4yvKicA7gVdJeij9eW0O\ncZgVZUVTS8H9A2ZjWdmbhiLi1yR7GpjtcnoXm3tr4+55h2I2atxoaVaAF5vb2dK5lYWuEVgFcSIw\nK8DK3jWGChwxZDaWORGYFWDbqqNOBFZBnAjMCrCyqZWpE2rZc/rEvEMxGzVOBGYFSEYM7ZZ5sTmz\nXYETgVkBVja1uqPYKk5Fr4f76Z88yn/+/k95h1F1aiRec9jefPqsQ6iftus2ofzogVVc+uNH2Nqz\nfVmInoC318/LMSqz0VfRieCkA+qZ4d2gym7jli6uv/857vljE5943cG85ei5u1xTSkTw7bufZt7M\nKbzu8L23Ha+tEW87xonAKktFJ4LTD9mT0w/ZM+8wqtK7T9iXy368nH+48RFuevB5vnDuYew7a9dp\nUvntinWsaGrlyrccwZuOnpt3OGYl5T4CK4n995jG9Ytezj+94VCWr9rEGV+9h6t+tYLurT15h5bJ\nNb99lt2nTtihNmBWqZwIrGRqasT5x+/LHZeczMkH1vPFnz3B2d/8DctXbco7tCE9v7GNXzz+F952\nzDzvJmZVwYnASm6vGZNY/K5Grjr/KJpaOjjnW7/m8//zB7Z0ducd2oCuTQcYvOO4hpwjMSsPJwIr\nmzMP3ZtfXHIybzumgX/732f4q3+9h3v+OLZ2n2vv2soP7n+O0w/ek7kzvZuYVQcnAiurGZPH84Vz\nD+P6RcczvqaGd119H5dc/xDrWzvzDg2AW5evZn1rJ+8+YX7eoZiVjROB5eK4BbO49eJXctGr9ufm\nh1/g9K/8ipsefJ7IeSvHa373JxbWT+WEhbNyjcOsnHJJBJLOlPSkpKclXZpHDJa/SeNr+bszDuKn\nH3kFDbtP4aPXP8QF37+f59ZvySWeh57byMPPbeRdL5+/y817MBuJPLaqrAW+BbwGOAQ4T9Ih5Y7D\nxo6X7DWdH33wBC5//SHc/+x6zvjqPXzv18/sMKO3HP79d88ydUIt5x41p6zlmuUtjxrBscDTEbEy\nIjqBHwDn5BCHjSG1NeI9J+7HHZeczPELdudzP/0D5377Nzy+urks5a9r6eCnj6zmTUfPZdokz0a3\n6pLHzOI5wHN9nq8CjsshDhuD5tRN5uoLjuGWR1bzmZsf4/Xf+DVnvHRPJo0r7Xj+VRva6Ozu4V0v\n37ek5ZiNRXkkgoEaX3dqA5C0CFgE0NDg8dzVRBJnH7EPr9x/Nl+67Ql+s2JtWco979h57L/HtLKU\nZTaW5JEIVgF9V+2aC7zQ/6SIWAwsBmhsbMx3KInlYubUCXzxTYfnHYZZxcujj+B+4ABJ+0maALwd\nuDmHOMzMjBxqBBHRLelvgJ8DtcDVEfFYueMwM7NELstQR8StwK15lG1mZjvyzGIzsyrnRGBmVuWc\nCMzMqpwTgZlZlXMiMDOrcsp72d8sJG0Cnup3eAawaZDnfR/PBkZzamr/ckd6/mCvZz1e6fdhsNd8\nHwY+Vsjz0bwXvg9DxzeScwv5jOh/bN+IqB82iogY8z/A4uGO9X3e7/HSUscykvMHez3r8Uq/D8X8\n9/d9yHxfRu1e+D4Udy+ynFvIZ0Sh/x16f3aVpqFbMhy7ZYjXSh3LSM4f7PWsxyv9Pgz2mu/DwMcK\nfT5afB+Ku3aWcwv5jCjq79olmoZGQtLSiGjMO468+T4kfB+2871I+D5UR2fx4rwDGCN8HxK+D9v5\nXiSq/j5UfI3AzMyGVg01AjMzG4ITgZlZlXMiMDOrclWXCCRNlXSNpH+T9I6848mLpAWSvifpxrxj\nyZOkN6TvhZ9IOiPvePIi6WBJV0m6UdIH844nT+lnxAOSzso7lnKpiEQg6WpJayQ92u/4mZKelPS0\npEvTw+cCN0bE+4Czyx5sCRVyHyJiZURcmE+kpVXgfbgpfS9cALwth3BLpsD78HhEfAB4K1BRQykL\n/HwA+DhwQ3mjzFdFJAJgCXBm3wOSaoFvAa8BDgHOk3QIyR7Jz6WnbS1jjOWwhOz3oZItofD78Mn0\n9UqyhALug6SzgV8Dd5Y3zJJbQsb7IOl04A/AX8odZJ4qIhFExD3A+n6HjwWeTr/5dgI/AM4BVpEk\nA6iQv79XgfehYhVyH5T4EvCziFhW7lhLqdD3Q0TcHBEnABXVZFrgfTgVOB74a+B9kirqM2IwuWxV\nWSZz2P7NH5IEcBzwdeCbkl5HaaeZjxUD3gdJs4DPAy+TdFlEfCGX6MpnsPfDRcDpwAxJ+0fEVXkE\nV0aDvR9OIWk2nUh1bCM74H2IiL8BkHQBsDYienKIrewqORFogGMREa3Ae8odTI4Guw/rgA+UO5gc\nDXYfvk7y5aBaDHYf7gbuLm8ouRrwPmx7ELGkfKHkr5KrPauAeX2ezwVeyCmWPPk+JHwfEr4PCd+H\nPio5EdwPHCBpP0kTgLcDN+ccUx58HxK+Dwnfh4TvQx8VkQgkXQf8DjhI0ipJF0ZEN/A3wM+Bx4Eb\nIuKxPOMsNd+HhO9Dwvch4fswPC86Z2ZW5SqiRmBmZsVzIjAzq3JOBGZmVc6JwMysyjkRmJlVOScC\nM7Mq50RguZAUkq7s8/xjkv7vKF17iaQ3j8a1hinnLZIel3RXv+P79O7zIOlISa8dxTLrJH1ooLLM\niuVEYHnpAM6VNDvvQPpKlyfO6kLgQxFxat+DEfFCRPQmoiOBghKBpKHWAKsDtiWCfmWZFcWJwPLS\nDSwG/rb/C/2/0UtqSf89RdL7HbaCAAADj0lEQVSvJN0g6Y+SvijpHZLuk7Rc0sI+lzld0v+m552V\n/n6tpC9Lul/SI5Le3+e6d0n6L2D5APGcl17/0XTJaiR9GngFcJWkL/c7f3567gTgs8DbJD0k6W1K\ndr+6Oo3hQUnnpL9zgaQfSroFuF3SbpLulLQsLbt36fAvAgvT6325t6z0GpMkfT89/0FJp/a59o8l\n3SbpKUlX9LkfS9JYl0va6b+FVYdKXn3Uxr5vAY/0fjBldARwMMn68iuB70bEsZIuJllS+qPpefOB\nk4GFwF2S9gfeBWyKiGMkTQR+I+n29PxjgUMj4pm+hUnaB/gScDSwgeRD+g0R8VlJrwI+FhFLBwo0\nIjrThNHYZ3njfwZ+GRHvlVQH3CfpF+mvvBw4PCLWp7WCN0ZEc1pr+r2km4FL0ziPTK83v0+RH07L\nPUzSS9JYD0xfOxJ4GUlN7ElJ3wD2AOZExKHpteqGvvVWqVwjsNxERDPw78BHCvi1+yNidUR0ACuA\n3g/y5SQf/r1uiIieiHiKJGG8BDgDeJekh4B7gVnAAen59/VPAqljgLsjoildn+Za4KQC4u3vDODS\nNIa7gUlAQ/raHRHRu4GKgH+W9AjwC5L18/cc5tqvAP4DICKeAP4E9CaCOyNiU0S0k+zAtS/JfVkg\n6RuSzgSaR/B32S7MNQLL278Cy4Dv9znWTfolRZKACX1e6+jzuKfP8x52fD/3X0QrSD5cL4qIn/d9\nQcmmLK2DxDfQuvUjIeBNEfFkvxiO6xfDO4B64OiI6JL0LEnSGO7ag+l737YC4yJig6QjgL8iqU28\nFXhvpr/CKoprBJar9BvwDSQdr72eJWmKgWT7wPFFXPotkmrSfoMFwJMkK01+UNJ4AEkHSpo6zHXu\nBU6WNDvtSD4P+FUBcWwGpvV5/nPgojTBIellg/zeDGBNmgROJfkGP9D1+rqHdJvJtEmogeTvHlDa\n5FQTET8CPgUclekvsorjRGBjwZVA39FD/0by4XsfyXaSg31bH8qTJB/YPwM+kDaJfJekWWRZ2sH6\nHYapFUfEauAy4C7gYWBZRPykgDjuAg7p7SwGPkeS2B5JY/jcIL93LdAoaSnJh/sTaTzrSPo2Hu3f\nSQ18G6iVtBy4HrggbUIbzBzg7rSZakn6d1oV8jLUZmZVzjUCM7Mq50RgZlblnAjMzKqcE4GZWZVz\nIjAzq3JOBGZmVc6JwMysyjkRmJlVuf8P1kmZwWD9wNUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x60ff3b550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_letters=[]\n",
    "M_initial=np.random.rand(4, 4)-0.5\n",
    "for i in range(1, 40000, 25):\n",
    "    M, e=trainlms(A, B, M_initial, ni, i)\n",
    "    num_letters.append(np.sum(np.round(np.dot(M, A))==B))\n",
    "\n",
    "plt.plot(list(range(1, 40000, 25)), num_letters)\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Number of correct letters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.2 Effect of larger number of associations\n",
    "\n",
    "This experiment demonstrates the capacity of the associative memory. What is the capacity of a $4\\times 4$ correlation matrix based associative memory?\n",
    "\n",
    "For additional pair '*auto*'-'*mrak*' create vectors $a_5$ and $b_5$ as explained in the previous part of the exercise. Create new matrices A and B with dimensions $4$ (rows) $\\times$ $5$ (columns) in the same way as previously explained. Initialize the matrix $\\mathbf{M}$ with random starting values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a5=real(\"auto\")\n",
    "b5=real(\"mrak\")\n",
    "\n",
    "A=np.hstack([a1, a2, a3, a4, a5])\n",
    "B=np.hstack([b1, b2, b3, b4, b5])\n",
    "\n",
    "M=np.random.rand(4, 4)-0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the *trainlms* function in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEOCAYAAACTqoDjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b068048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ni=0.9999/max(np.linalg.eig(np.dot(A, A.T))[0])\n",
    "M, e=trainlms(A, B, M, ni, 100000)\n",
    "print(np.sum(np.round(np.dot(M, A))==B))\n",
    "\n",
    "plt.plot(e)\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasks**\n",
    "\n",
    "1. How many iterations did you use?\n",
    "2. How many characters were memorized correctly?\n",
    "3. What is the SSE error?\n",
    "4. What happens if we call the function from the beginning?\n",
    "5. How many characters are correctly memorized now and how large is the mistake? Is there any difference and why?\n",
    "6. Is it possible to train this network in order to memorize all five associations?\n",
    "7. Why? (Explain the previous answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
