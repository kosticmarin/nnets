{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 6 Support Vector Machine\n",
    "## 6.1 Kernels\n",
    "Support Vector Machine can [use different kernels](https://en.wikipedia.org/wiki/Kernel_method): linear, radial basis function, polynomial, sigmoid, etc. The difference between some of them can be seen after running the code below that uses a classical example. Besides the usual packages, the *sklearn* package is also used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "\n",
    "#take the well-known iris dataset\n",
    "iris = datasets.load_iris()\n",
    "#we will use only sepal length and width\n",
    "x=iris.data[:, :2]\n",
    "y=iris.target\n",
    "\n",
    "#plot points\n",
    "x1, x2=x[:, 0], x[:, 1]\n",
    "x_min, x_max=x1.min()-1, x1.max()+1\n",
    "y_min, y_max=x2.min()-1, x2.max()+1\n",
    "h=0.02\n",
    "plot_x, plot_y=np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "#regularization\n",
    "C=1.0  \n",
    "models=(svm.SVC(kernel=\"linear\", C=C),\n",
    "          svm.SVC(kernel=\"rbf\", gamma=0.7, C=C),\n",
    "          svm.SVC(kernel=\"poly\", degree=3, C=C))\n",
    "models=(model.fit(x, y) for model in models)\n",
    "\n",
    "# title for the plots\n",
    "titles = (\"Linear kernel\", \"RBF kernel\", \"Polynomial (degree 3) kernel\")\n",
    "\n",
    "\n",
    "for model, title in zip(models, titles):\n",
    "    points=model.predict(np.c_[plot_x.ravel(), plot_y.ravel()]).reshape(plot_x.shape)\n",
    "    plt.contourf(plot_x, plot_y, points, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "    plt.xlim(plot_x.min(), plot_x.max())\n",
    "    plt.ylim(plot_y.min(), plot_y.max())\n",
    "    plt.xlabel(\"Sepal length\")\n",
    "    plt.ylabel(\"Sepal width\")\n",
    "    plt.title(title)\n",
    "    \n",
    "    predicted=model.predict(x);\n",
    "    print(\"Accuracy: %.2lf%%\"%(100*np.sum(y==predicted)/y.size))\n",
    "    \n",
    "    plt.scatter(x1, x2, c=y, cmap=plt.cm.coolwarm, s=20, edgecolors=\"k\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasks**\n",
    "\n",
    "1. What accuracies are achieved when other features are used as well?\n",
    "2. Split the dataset into a training and testing part, fit the SVM model on the training part, and test it on the testing part. What gives the highest accuracy?\n",
    "3. Make the code below give over 90% accuracy and then explain how you achieved it and why did it work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm, datasets\n",
    "\n",
    "n1=400\n",
    "n2=400\n",
    "\n",
    "class1=(np.tile(np.random.uniform(low=0.0, high=1, size=n2).reshape((n2, 1)), (1, 2))+3/2)*\\\n",
    "np.array([(np.cos(a), np.sin(a)) for a in np.random.uniform(low=2, high=8, size=n2)])+np.tile(np.array([[3/2, 0]]), (n1, 1))\n",
    "class2=(np.tile(np.random.uniform(low=0.0, high=1, size=n2).reshape((n2, 1)), (1, 2))+3/2)*\\\n",
    "np.array([(np.cos(a), np.sin(a)) for a in np.random.uniform(low=-1, high=4, size=n2)])\n",
    "x=np.vstack((class1, class2))\n",
    "y=np.concatenate((np.ones((n1)), 2*np.ones((n2))))\n",
    "\n",
    "idx=np.random.permutation(y.size)\n",
    "x=x[idx, :]\n",
    "y=y[idx]\n",
    "\n",
    "s=round((n1+n2)/2)\n",
    "#s=600\n",
    "\n",
    "x_train=x[:s, :]\n",
    "y_train=y[:s]\n",
    "\n",
    "x_test=x[s:, :]\n",
    "y_test=y[s:]\n",
    "\n",
    "#EDIT ONLY FROM HERE...\n",
    "model=svm.SVC(kernel=\"linear\")\n",
    "model.fit(x_train, y_train)\n",
    "#...TO HERE\n",
    "\n",
    "predicted=model.predict(x_test);\n",
    "print(\"Accuracy: %.2lf%%\"%(100*np.sum(y_test==predicted)/y_test.size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Wine dataset\n",
    "Here we are going to make some experiments with the wine dataset to see how features can [affect](https://en.wikipedia.org/wiki/Feature_selection) the classification.\n",
    "\n",
    "**Tasks**\n",
    "\n",
    "1. Which SVM kernel will achieve the highest accuracy when all features are used?\n",
    "2. If you can use **only one** feature and any kernel to achieve highest possible accuracy, which feature and kernel would that be?\n",
    "3. If you can use **only two** features and any kernel to achieve highest possible accuracy, which feature and kernel would that be?\n",
    "4. How do you explain the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "wine=load_wine()\n",
    "x=wine.data\n",
    "y=wine.target\n",
    "idx=np.random.permutation(y.size)\n",
    "x=x[idx, :]\n",
    "y=y[idx]\n",
    "\n",
    "#all features\n",
    "features_idx=range(x.shape[1])\n",
    "#only some of the features\n",
    "#features_idx=[0, 1]\n",
    "\n",
    "x=x[:, features_idx]\n",
    "\n",
    "s=round(y.size/2)\n",
    "\n",
    "x_train=x[:s, :]\n",
    "y_train=y[:s]\n",
    "\n",
    "x_test=x[s:, :]\n",
    "y_test=y[s:]\n",
    "\n",
    "model=svm.SVC()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "predicted=model.predict(x_test);\n",
    "print(\"Accuracy: %.2lf%%\"%(100*np.sum(y_test==predicted)/y_test.size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Speed\n",
    "SVM is really great, but it has an important disadvantage with respect to neural networks in general. Here we are going to demonstrate it.\n",
    "\n",
    "**Tasks**\n",
    "1. Run the code below for various dataset sizes and each time store the time needed for the model to fit.\n",
    "2. Draw a plot that shows the influence of dataset size on execution time.\n",
    "3. How would you model the influence?\n",
    "4. How would you model the same influence in case of multilayer perceptron?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm, datasets\n",
    "\n",
    "def create_data(n1, n2):\n",
    "    class1=np.c_[np.random.normal(0, 1, size=n1), np.random.normal(0, 1, size=n1)]\n",
    "    class2=np.c_[np.random.normal(2, 1, size=n2), np.random.normal(0, 1, size=n2)]\n",
    "    x=np.vstack((class1, class2))\n",
    "    y=np.concatenate((np.ones((n1)), 2*np.ones((n2))))\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "x, y=create_data(5000, 5000)\n",
    "model=svm.SVC(kernel=\"linear\", C=1.0)\n",
    "import time;\n",
    "start=time.time()\n",
    "model.fit(x, y)\n",
    "end=time.time();\n",
    "t=end-start\n",
    "print(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
